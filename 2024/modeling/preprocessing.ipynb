{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd7d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7739b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flights originating from WA: 49168\n",
      "   MONTH  DAY_OF_MONTH  DAY_OF_WEEK OP_UNIQUE_CARRIER ORIGIN ORIGIN_STATE_ABR  \\\n",
      "0      4             1            1                AA    GEG               WA   \n",
      "1      4             1            1                AA    GEG               WA   \n",
      "2      4             1            1                AA    GEG               WA   \n",
      "3      4             1            1                AA    GEG               WA   \n",
      "4      4             1            1                AA    SEA               WA   \n",
      "\n",
      "  DEST DEST_STATE_ABR  CRS_DEP_TIME  DEP_DELAY  DEP_DELAY_NEW  DEP_DEL15  \\\n",
      "0  DFW             TX          5.25       11.0           11.0        0.0   \n",
      "1  DFW             TX         13.32       12.0           12.0        0.0   \n",
      "2  PHX             AZ          6.75       -6.0            0.0        0.0   \n",
      "3  PHX             AZ         15.12       -6.0            0.0        0.0   \n",
      "4  CLT             NC          6.00       -2.0            0.0        0.0   \n",
      "\n",
      "   DEP_DELAY_GROUP  TAXI_OUT  CRS_ELAPSED_TIME  DISTANCE  DISTANCE_GROUP  \\\n",
      "0              0.0      13.0               211      1477               6   \n",
      "1              0.0      16.0               223      1477               6   \n",
      "2             -1.0      13.0               173      1020               5   \n",
      "3             -1.0      13.0               173      1020               5   \n",
      "4             -1.0      29.0               306      2279              10   \n",
      "\n",
      "  ORIGIN-DEST  \n",
      "0     GEG-DFW  \n",
      "1     GEG-DFW  \n",
      "2     GEG-PHX  \n",
      "3     GEG-PHX  \n",
      "4     SEA-CLT  \n",
      "✅ Saved filtered dataset as 'clean_data_WA.csv'\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Filter dataset: only keep flights originating from Washington (WA)\n",
    "# ===============================\n",
    "\n",
    "# Read your dataset (replace file name if needed)\n",
    "df = pd.read_csv(r'D:\\Project DS Final\\2024\\preprocessing\\data_clean_final_2024.csv')\n",
    "\n",
    "# Filter rows where ORIGIN_STATE_ABR == 'WA'\n",
    "df_wa = df[df['ORIGIN_STATE_ABR'] == 'WA']\n",
    "\n",
    "# Reset index for clarity\n",
    "df_wa = df_wa.reset_index(drop=True)\n",
    "\n",
    "# Display result\n",
    "print(\"Number of flights originating from WA:\", len(df_wa))\n",
    "print(df_wa.head())\n",
    "\n",
    "# (Optional) Save the filtered dataset\n",
    "df_wa.to_csv(\"clean_data_WA.csv\", index=False)\n",
    "print(\"✅ Saved filtered dataset as 'clean_data_WA.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592cf582",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'clean_data_encode.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m df_selected = df[selected_features]\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ---- Save the filtered dataset ----\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mdf_selected\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclean_data_encode.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Saved dataset with selected features as \u001b[39m\u001b[33m'\u001b[39m\u001b[33mclean_data_encode.csv\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, df_selected.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'clean_data_encode.csv'"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Select specific features for encoding\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read your dataset (change file name if needed)\n",
    "df = pd.read_csv(\"clean_data_WA.csv\")\n",
    "\n",
    "# ---- Choose only the features you want to keep ----\n",
    "selected_features = [\n",
    "    'MONTH',\n",
    "    'DAY_OF_MONTH',\n",
    "    'DAY_OF_WEEK',\n",
    "    'OP_UNIQUE_CARRIER',\n",
    "    'ORIGIN',\n",
    "    'DEST',\n",
    "    'CRS_DEP_TIME',\n",
    "    'TAXI_OUT',\n",
    "    'CRS_ELAPSED_TIME',\n",
    "    'DISTANCE',\n",
    "    'DEP_DELAY'\n",
    "]\n",
    "\n",
    "# Filter dataset\n",
    "df_selected = df[selected_features]\n",
    "\n",
    "# ---- Save the filtered dataset ----\n",
    "df_selected.to_csv(\"clean_data_encode.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved dataset with selected features as 'clean_data_encode.csv'\")\n",
    "print(\"Shape:\", df_selected.shape)\n",
    "print(df_selected.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cyclical + OneHot Encoding for Time Features\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d709cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "df = pd.read_csv(\"clean_data_encode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Time features encoded successfully!\n",
      "New shape: (49168, 16)\n",
      "  OP_UNIQUE_CARRIER ORIGIN DEST  TAXI_OUT  CRS_ELAPSED_TIME  DISTANCE  \\\n",
      "0                AA    GEG  DFW      13.0               211      1477   \n",
      "1                AA    GEG  DFW      16.0               223      1477   \n",
      "2                AA    GEG  PHX      13.0               173      1020   \n",
      "3                AA    GEG  PHX      13.0               173      1020   \n",
      "4                AA    SEA  CLT      29.0               306      2279   \n",
      "\n",
      "   DEP_DELAY  DAY_OF_MONTH_sin  DAY_OF_MONTH_cos  DAY_OF_WEEK_sin  \\\n",
      "0       11.0          0.201299           0.97953         0.781831   \n",
      "1       12.0          0.201299           0.97953         0.781831   \n",
      "2       -6.0          0.201299           0.97953         0.781831   \n",
      "3       -6.0          0.201299           0.97953         0.781831   \n",
      "4       -2.0          0.201299           0.97953         0.781831   \n",
      "\n",
      "   DAY_OF_WEEK_cos  CRS_DEP_TIME_sin  CRS_DEP_TIME_cos  MONTH_4  MONTH_5  \\\n",
      "0          0.62349          0.980785      1.950903e-01        1        0   \n",
      "1          0.62349         -0.338738     -9.408808e-01        1        0   \n",
      "2          0.62349          0.980785     -1.950903e-01        1        0   \n",
      "3          0.62349         -0.728969     -6.845471e-01        1        0   \n",
      "4          0.62349          1.000000      6.123234e-17        1        0   \n",
      "\n",
      "   MONTH_6  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n"
     ]
    }
   ],
   "source": [
    "# ---- 1. Cyclical encoding for DAY_OF_MONTH (1–31) ----\n",
    "df['DAY_OF_MONTH_sin'] = np.sin(2 * np.pi * df['DAY_OF_MONTH'] / 31)\n",
    "df['DAY_OF_MONTH_cos'] = np.cos(2 * np.pi * df['DAY_OF_MONTH'] / 31)\n",
    "\n",
    "# ---- 2. Cyclical encoding for DAY_OF_WEEK (1–7) ----\n",
    "df['DAY_OF_WEEK_sin'] = np.sin(2 * np.pi * df['DAY_OF_WEEK'] / 7)\n",
    "df['DAY_OF_WEEK_cos'] = np.cos(2 * np.pi * df['DAY_OF_WEEK'] / 7)\n",
    "\n",
    "# ---- 3. Cyclical encoding for CRS_DEP_TIME (0–24h) ----\n",
    "# Ensure CRS_DEP_TIME is within [0, 24)\n",
    "df['CRS_DEP_TIME_sin'] = np.sin(2 * np.pi * df['CRS_DEP_TIME'] / 24)\n",
    "df['CRS_DEP_TIME_cos'] = np.cos(2 * np.pi * df['CRS_DEP_TIME'] / 24)\n",
    "\n",
    "# ---- 4. One-Hot encoding for MONTH (only 3 unique values) ----\n",
    "month_dummies = pd.get_dummies(df['MONTH'], prefix='MONTH', dtype=int)\n",
    "\n",
    "# ---- 5. Concatenate all new columns ----\n",
    "df_encoded = pd.concat([df, month_dummies], axis=1)\n",
    "\n",
    "# ---- 6. Drop original time columns (optional) ----\n",
    "df_encoded = df_encoded.drop(columns=['MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'CRS_DEP_TIME'])\n",
    "\n",
    "# ---- 7. Save the encoded dataset ----\n",
    "df_encoded.to_csv(\"encoded_time_features.csv\", index=False)\n",
    "\n",
    "print(\"✅ Time features encoded successfully!\")\n",
    "print(\"New shape:\", df_encoded.shape)\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c5b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f880e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved DEST frequency statistics to 'dest_value_counts.csv'\n",
      "   DEST  count\n",
      "84  JAC     22\n",
      "83  RSW     37\n",
      "82  GTF     45\n",
      "81  MRY     58\n",
      "80  MSO     74\n",
      "\n",
      "Top DESTs:\n",
      "   DEST  count\n",
      "4  LAS   2158\n",
      "3  SEA   2176\n",
      "2  LAX   2182\n",
      "1  PHX   2335\n",
      "0  DEN   2478\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Count frequency of each DEST and export to CSV\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read your dataset (change filename if needed)\n",
    "df = pd.read_csv(\"encoded_time_features.csv\")\n",
    "\n",
    "# ---- Count number of flights per DEST ----\n",
    "dest_counts = df['DEST'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "dest_counts.columns = ['DEST', 'count']\n",
    "\n",
    "# ---- Sort from least to most frequent ----\n",
    "dest_counts = dest_counts.sort_values(by='count', ascending=True)\n",
    "\n",
    "# ---- Export to CSV ----\n",
    "dest_counts.to_csv(\"dest_value_counts.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved DEST frequency statistics to 'dest_value_counts.csv'\")\n",
    "print(dest_counts.head())\n",
    "print(\"\\nTop DESTs:\\n\", dest_counts.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2924bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered dataset saved as 'clean_data_dest_filtered.csv'\n",
      "Number of DEST kept: 21\n",
      "Shape after filtering: (32002, 16)\n",
      "DEST kept:\n",
      " ['DEN', 'PHX', 'LAX', 'SEA', 'LAS', 'ANC', 'SLC', 'SFO', 'PDX', 'ORD', 'DFW', 'BOI', 'SAN', 'GEG', 'SJC', 'SMF', 'ATL', 'MSP', 'SNA', 'OAK', 'JFK']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Filter dataset: keep only DEST with more than 789 records\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "\n",
    "# Read your dataset (change file name if needed)\n",
    "df = pd.read_csv(\"encoded_time_features.csv\")\n",
    "\n",
    "# ---- Count number of flights per DEST ----\n",
    "dest_counts = df['DEST'].value_counts()\n",
    "\n",
    "# ---- Get list of DEST with count > 789 ----\n",
    "valid_dests = dest_counts[dest_counts > 789].index\n",
    "\n",
    "# ---- Filter dataset ----\n",
    "df_filtered = df[df['DEST'].isin(valid_dests)].reset_index(drop=True)\n",
    "\n",
    "# ---- Save filtered dataset ----\n",
    "df_filtered.to_csv(\"clean_data_dest_filtered.csv\", index=False)\n",
    "\n",
    "print(\"✅ Filtered dataset saved as 'clean_data_dest_filtered.csv'\")\n",
    "print(\"Number of DEST kept:\", len(valid_dests))\n",
    "print(\"Shape after filtering:\", df_filtered.shape)\n",
    "print(\"DEST kept:\\n\", valid_dests.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ One-Hot encoding completed successfully!\n",
      "New shape: (32002, 51)\n",
      "Encoded columns:\n",
      "['CARRIER_AA', 'CARRIER_AS', 'CARRIER_B6', 'CARRIER_DL', 'CARRIER_F9', 'CARRIER_G4', 'CARRIER_MQ', 'CARRIER_NK', 'CARRIER_OO', 'CARRIER_UA', 'CARRIER_WN', 'ORIGIN_ALW', 'ORIGIN_BLI', 'ORIGIN_GEG', 'ORIGIN_PAE', 'ORIGIN_PSC', 'ORIGIN_SEA', 'DEST_ANC', 'DEST_ATL', 'DEST_BOI', 'DEST_DEN', 'DEST_DFW', 'DEST_GEG', 'DEST_JFK', 'DEST_LAS', 'DEST_LAX', 'DEST_MSP', 'DEST_OAK', 'DEST_ORD', 'DEST_PDX', 'DEST_PHX', 'DEST_SAN', 'DEST_SEA', 'DEST_SFO', 'DEST_SJC', 'DEST_SLC', 'DEST_SMF', 'DEST_SNA']\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# One-Hot Encoding for categorical features:\n",
    "# OP_UNIQUE_CARRIER, ORIGIN, DEST\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read your dataset\n",
    "df = pd.read_csv(\"clean_data_dest_filtered.csv\")\n",
    "\n",
    "# ---- Define allowed categories ----\n",
    "carrier_list = ['AA', 'AS', 'B6', 'DL', 'F9', 'G4', 'HA', 'MQ', 'NK', 'OO', 'UA', 'WN']\n",
    "origin_list  = ['ALW', 'BLI', 'GEG', 'PAE', 'PSC', 'SEA']\n",
    "dest_list    = ['JFK', 'OAK', 'SNA', 'MSP', 'ATL', 'SMF', 'SJC', 'GEG', 'SAN', 'BOI',\n",
    "                'DFW', 'ORD', 'PDX', 'SFO', 'SLC', 'ANC', 'LAS', 'SEA', 'LAX', 'PHX', 'DEN']\n",
    "\n",
    "# ---- Ensure columns only contain known categories ----\n",
    "df = df[df['OP_UNIQUE_CARRIER'].isin(carrier_list)]\n",
    "df = df[df['ORIGIN'].isin(origin_list)]\n",
    "df = df[df['DEST'].isin(dest_list)]\n",
    "\n",
    "# ---- One-Hot Encoding ----\n",
    "df_encoded = pd.get_dummies(\n",
    "    df,\n",
    "    columns=['OP_UNIQUE_CARRIER', 'ORIGIN', 'DEST'],\n",
    "    prefix=['CARRIER', 'ORIGIN', 'DEST'],\n",
    "    dtype=int  # ensure 0/1 instead of True/False\n",
    ")\n",
    "\n",
    "# ---- Save encoded dataset ----\n",
    "df_encoded.to_csv(\"clean_data_encoded_onehot.csv\", index=False)\n",
    "\n",
    "print(\"✅ One-Hot encoding completed successfully!\")\n",
    "print(\"New shape:\", df_encoded.shape)\n",
    "print(\"Encoded columns:\")\n",
    "print([col for col in df_encoded.columns if any(prefix in col for prefix in ['CARRIER_', 'ORIGIN_', 'DEST_'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebd867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scaled numeric features using StandardScaler\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"clean_data_encoded_onehot.csv\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['TAXI_OUT', 'CRS_ELAPSED_TIME', 'DISTANCE']\n",
    "\n",
    "# Fit & transform\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "print(\"✅ Scaled numeric features using StandardScaler\")\n",
    "df.to_csv(\"clean_data_scaled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "812185eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (32002, 51)\n",
      "Filtered dataset shape: (29537, 51)\n",
      "✅ Data with DEP_DELAY > 300 removed and saved to 'clean_data_scaled_new.csv'\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Remove all data where DEP_DELAY > 300\n",
    "# ====================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace with your current file name)\n",
    "df = pd.read_csv(\"clean_data_scaled.csv\")\n",
    "\n",
    "# Display original shape\n",
    "print(\"Original dataset shape:\", df.shape)\n",
    "\n",
    "# Filter out rows where DEP_DELAY > 300\n",
    "filtered_df = df[df[\"DEP_DELAY\"] <= 44]\n",
    "\n",
    "# Display new shape after filtering\n",
    "print(\"Filtered dataset shape:\", filtered_df.shape)\n",
    "\n",
    "# Save the cleaned dataset to a new file\n",
    "filtered_df.to_csv(\"clean_data_scaled_new.csv\", index=False)\n",
    "\n",
    "print(\"✅ Data with DEP_DELAY > 300 removed and saved to 'clean_data_scaled_new.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e29574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af842003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
